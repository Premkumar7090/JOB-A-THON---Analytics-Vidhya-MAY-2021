{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "jobathon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hearing-partition"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1PZrItIUNQdS3sAyTz18sB60os1fWUc8Y#scrollTo=P7pmhsHW6ErY\" \n",
        "target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "id": "hearing-partition"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "accompanied-ready"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "<h1 style=\"font-family:verdana;\"> Description:</h1> \n",
        "\n",
        "<ul>\n",
        "<li><p style=\"font-family:verdana;\">\n",
        "In this notebook, we are going to predict the lead of Credit Card, using various features such as Gender, Age, Region_Code, Occupation, Channel_Code, Vintage, Credit_Product, Avg_Account_Balance, Is_Active.\n",
        "</p></li>\n",
        "    \n",
        "<li><p style=\"font-family:verdana;\">\n",
        "The dataset we are going to use is the Credit Card Lead Prediction dataset from Analytics Vidhya which contains about 245725 rows and 10 features that can be downloaded <a href=\"https://datahack.analyticsvidhya.com/contest/job-a-thon\">here</a>.\n",
        "</p></li> \n",
        "\n",
        "<li><p style=\"font-family:verdana;\">\n",
        "The dataset contains the labels which we have to predict and the labels are continuous. So the problem we have is a Supervised Regression type.\n",
        "</p></li>  \n",
        "</ul>\n",
        "\n",
        "</div>"
      ],
      "id": "accompanied-ready"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "commercial-remark"
      },
      "source": [
        "## Step 0: Import libraries and dataset"
      ],
      "id": "commercial-remark"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "infinite-gathering"
      },
      "source": [
        "# Importing All Required libraries\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from pylab import rcParams\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
        "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn import metrics"
      ],
      "id": "infinite-gathering",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coastal-submission"
      },
      "source": [
        "# Importing Datasets of train file and test file\n",
        "\n",
        "train=pd.read_csv(\"/content/train_s3TEQDk.csv\")\n",
        "test=pd.read_csv(\"/content/test_mSzZ8RL.csv\")\n"
      ],
      "id": "coastal-submission",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gorgeous-operations"
      },
      "source": [
        "## Step 1: Descriptive analysis"
      ],
      "id": "gorgeous-operations"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eleven-customer"
      },
      "source": [
        " Preview training dataset\n",
        "train.head()"
      ],
      "id": "eleven-customer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "floppy-brisbane"
      },
      "source": [
        "# Preview testing dataset\n",
        "test.head()"
      ],
      "id": "floppy-brisbane",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "middle-leather"
      },
      "source": [
        "# Training dataset dimensions - (rows, columns)\n",
        "print('Training data: \\nRows: {} Columns: {}'.format(train.shape[0], train.shape[1]))"
      ],
      "id": "middle-leather",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clinical-chick"
      },
      "source": [
        "# Testing dataset dimensions - (rows, columns)\n",
        "print('Testing data: \\nRows: {} Columns: {}'.format(test.shape[0], test.shape[1]))"
      ],
      "id": "clinical-chick",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ready-integral"
      },
      "source": [
        "# Features data-type\n",
        "train.info()"
      ],
      "id": "ready-integral",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "legendary-sector"
      },
      "source": [
        "# Statistical summary\n",
        "train.describe().T"
      ],
      "id": "legendary-sector",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "logical-douglas"
      },
      "source": [
        "# Checking for Null values\n",
        "round((train.isnull().sum() / train.shape[0]) * 100, 2).astype(str) + ' %'"
      ],
      "id": "logical-douglas",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adult-scratch"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "<h3 style=\"font-family:verdana;\"> Observations:</h3>\n",
        "\n",
        "<ul>\n",
        "    \n",
        "<li><p style=\"font-family:verdana;\">\n",
        "The feature 'Credit_Product' contains 31.57% null values, So we want to use label encoding technique to remove null values.\n",
        "</p>   \n",
        "    \n",
        "<li><p style=\"font-family:verdana;\">\n",
        "Here we observe some of the features has datatype  int and object, So we want to keep all same as int. so here we ise  same technique which is label encoding to put as all int in features.\n",
        "</p> \n",
        "</ul>\n",
        "\n",
        "</div>"
      ],
      "id": "adult-scratch"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bearing-breakdown"
      },
      "source": [
        "## Step 3: Data preprocessing"
      ],
      "id": "bearing-breakdown"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "systematic-dakota"
      },
      "source": [
        "### 3.1: Replacing dtype as str in 'Credit_Product' and 'Channel_Code' and 'Is_Active'"
      ],
      "id": "systematic-dakota"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "generic-spirit"
      },
      "source": [
        "train['Credit_Product']=train['Credit_Product'].astype(str)\n",
        "train['Channel_Code']=train['Channel_Code'].astype(str)\n",
        "train['Is_Active']=train['Is_Active'].astype(str)"
      ],
      "id": "generic-spirit",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "annual-bradford"
      },
      "source": [
        "### 3.2: Feature Encoding"
      ],
      "id": "annual-bradford"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "minus-matter"
      },
      "source": [
        "le = LabelEncoder()\n",
        "train['Gender']= le.fit_transform(train['Gender'])\n",
        "train['Occupation']= le.fit_transform(train['Occupation'])\n",
        "train['Credit_Product']= le.fit_transform(train['Credit_Product'])\n",
        "train['Vintage']= le.fit_transform(train['Vintage'])\n",
        "train['Region_Code']= le.fit_transform(train['Region_Code'])\n",
        "train['Channel_Code']= le.fit_transform(train['Channel_Code'])\n",
        "train['Age']= le.fit_transform(train['Age'])\n",
        "train['Is_Active']= le.fit_transform(train['Is_Active'])\n",
        "train['ID']= le.fit_transform(train['ID'])"
      ],
      "id": "minus-matter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wl0F0WjR7p2"
      },
      "source": [
        "test=pd.read_csv(\"/content/gdrive/MyDrive/Untitled form (File responses)/test_mSzZ8RL.csv\")\n",
        " \n",
        "test['Credit_Product']=test['Credit_Product'].astype(str)\n",
        "df=test.copy()\n",
        "lab=LabelEncoder()\n",
        "df[\"Gender\"]=lab.fit_transform(test[\"Gender\"])\n",
        "df[\"Occupation\"]=lab.fit_transform(test[\"Occupation\"])\n",
        "df[\"Credit_Product\"]=lab.fit_transform(test[\"Credit_Product\"])\n",
        "df[\"Is_Active\"]=lab.fit_transform(test[\"Is_Active\"])\n",
        "df[\"Channel_Code\"]=lab.fit_transform(test[\"Channel_Code\"])\n",
        "df[\"ID\"]=lab.fit_transform(test[\"ID\"])\n",
        "df[\"Age\"]=lab.fit_transform(test[\"Age\"])\n",
        "df[\"Region_Code\"]=lab.fit_transform(test[\"Region_Code\"])\n",
        "df[\"Vintage\"]=lab.fit_transform(test[\"Vintage\"])\n",
        "df[\"Avg_Account_Balance\"]=lab.fit_transform(test[\"Avg_Account_Balance\"])\n",
        "df.head()\n",
        " \n",
        " \n",
        "# target1=df.iloc[:,10:]\n",
        "input1=df.iloc[:,0:10]\n",
        "input1"
      ],
      "id": "3wl0F0WjR7p2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "willing-proceeding"
      },
      "source": [
        "### 3.3: Separating train into X and Y"
      ],
      "id": "willing-proceeding"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "working-liberia"
      },
      "source": [
        "target = 'Is_Lead'\n",
        "df1=train.copy()\n",
        "X = df1.loc[:, df1.columns!=target]\n",
        "Y = df1.loc[:, df1.columns==target]"
      ],
      "id": "working-liberia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exposed-grounds"
      },
      "source": [
        "## Step 4: Data Modelling"
      ],
      "id": "exposed-grounds"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuzzy-genetics"
      },
      "source": [
        "### 4.1: cat boost Regressor"
      ],
      "id": "fuzzy-genetics"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incredible-desire"
      },
      "source": [
        "from catboost import CatBoostRegressor\n",
        "best_params = {\n",
        "            'bagging_temperature': 0.5,\n",
        "            'depth': 8,\n",
        "            'iterations': 2000,\n",
        "            'l2_leaf_reg': 25,\n",
        "            'learning_rate': 0.0556,\n",
        "            'sampling_frequency': 'PerTreeLevel',\n",
        "            'leaf_estimation_method': 'Gradient',\n",
        "            'random_strength': 0.8,\n",
        "            'boosting_type': 'Ordered',\n",
        "            'feature_border_type': 'MaxLogSum',\n",
        "            'l2_leaf_reg': 50,\n",
        "            'max_ctr_complexity': 2,\n",
        "            'fold_len_multiplier': 2\n",
        "    }\n"
      ],
      "id": "incredible-desire",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "concerned-psychiatry"
      },
      "source": [
        "\n",
        "from catboost import CatBoostRegressor\n",
        "model = CatBoostRegressor(**best_params)\n",
        "model.fit(X,Y,verbose=1000)\n",
        "predictions_catboost = model.predict(input1)"
      ],
      "id": "concerned-psychiatry",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "genuine-spell"
      },
      "source": [
        "### 4.2: xgb classifier"
      ],
      "id": "genuine-spell"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN-NQCM_U4yu"
      },
      "source": [
        "import xgboost as xg\n",
        "from xgboost import XGBClassifier\n",
        " \n",
        "clf2 = xg.XGBClassifier(class_weight='balanced').fit(X_train, Y_train)\n",
        "Y_Test_Pred = clf2.predict(X_test)\n"
      ],
      "id": "RN-NQCM_U4yu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alleged-snowboard"
      },
      "source": [
        "## Step 5: Model Evaluation"
      ],
      "id": "alleged-snowboard"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nominated-nickel"
      },
      "source": [
        "def generate_model_report(y_actual, y_predicted):\n",
        "    print(\"Accuracy = \" , accuracy_score(y_actual, y_predicted))\n",
        "    print(\"Precision = \" ,precision_score(y_actual, y_predicted))\n",
        "    print(\"Recall = \" ,recall_score(y_actual, y_predicted))\n",
        "    print(\"F1 Score = \" ,f1_score(y_actual, y_predicted))\n",
        "    pass"
      ],
      "id": "nominated-nickel",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "generic-painting"
      },
      "source": [
        "def generate_auc_roc_curve(clf, X_test):\n",
        "    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test,  y_pred_proba)\n",
        "    auc = roc_auc_score(Y_test, y_pred_proba)\n",
        "    plt.plot(fpr,tpr,label=\"AUC ROC Curve with Area Under the curve =\"+str(auc))\n",
        "    plt.legend(loc=4)\n",
        "    plt.show()\n",
        "    pass"
      ],
      "id": "generic-painting",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ideal-despite"
      },
      "source": [
        "### Saving the model"
      ],
      "id": "ideal-despite"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "differential-shape"
      },
      "source": [
        "from joblib import dump, load\n",
        "dump(model, 'extra1.joblib')\n",
        "\n",
        "pre=load(\"extra1.joblib\")\n",
        "predicted=pre.predict(input1)\n",
        "ff=pd.DataFrame({\"ID\":input1[\"ID\"],\n",
        "                 \"Is_Lead\"\n",
        "                 :predicted})\n",
        "ff.to_csv ('dataframe.csv', index = None, header=True) "
      ],
      "id": "differential-shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "postal-chase"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "<h3 style=\"font-family:verdana;\"> Conclusion:</h3>\n",
        "\n",
        "<ul>\n",
        "    \n",
        "<li><p style=\"font-family:verdana;\">\n",
        "In this project, we tried to build a model using various algorithms such as svm, Decision tree regression, Random forest and XGB regressor and XGB Classifier to get the best possible prediction.\n",
        "</p></li>     \n",
        "        \n",
        "<li><p style=\"font-family:verdana;\">\n",
        "The hyperparameter tuned catboost regressor gives us the best roc_aucscore and r2 score for this problem.\n",
        "</p></li>    \n",
        "\n",
        "   \n",
        "\n",
        "</ul>\n",
        "\n",
        "</div>"
      ],
      "id": "postal-chase"
    }
  ]
}